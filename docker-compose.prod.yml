version: "3.9"

# Production stack: Caddy reverse proxy, static frontend, API (uvicorn),
# Celery worker, Redis. Includes ports, volumes, networks & healthchecks.

name: seo-analyzer-prod

networks:
  public_net:
    driver: bridge
  internal_net:
    driver: bridge
    internal: true

volumes:
  caddy_data:
  caddy_config:
  redis_data:
  app_data:

services:
  reverse-proxy:
    image: caddy:2-alpine
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - caddy_data:/data
      - caddy_config:/config
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
    depends_on:
      - frontend
      - api
    networks:
      - public_net
      - internal_net
    healthcheck:
      test: ["CMD-SHELL", "wget -q -O - http://localhost:80 > /dev/null 2>&1 || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  # Static frontend (serve built artefacts from ./frontend/dist)
  frontend:
    image: nginx:alpine
    restart: always
    expose:
      - "80"
    volumes:
      - ./frontend/dist:/usr/share/nginx/html:ro
      - ./deploy/nginx-default.conf:/etc/nginx/conf.d/default.conf:ro
    networks:
      - internal_net
    healthcheck:
      test: ["CMD-SHELL", "wget -q -O - http://localhost:80 >/dev/null 2>&1 || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  # Backend API (uvicorn) â€” built from existing backend Dockerfile
  api:
    image: seo-analyzer-api:latest
    build:
      context: .
      dockerfile: backend/Dockerfile
    restart: always
    expose:
      - "8000"
    env_file:
      - .env
    environment:
      # Use SQLite by default (shared via volume). Override DATABASE_URL in real prod if needed.
      - DATABASE_URL=${DATABASE_URL:-sqlite:////app/data/app.db}
      - REDIS_URL=redis://redis:6379/0
      - PYTHONUNBUFFERED=1
    # If your Dockerfile already starts uvicorn, you can remove the command below
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000
    depends_on:
      - redis
    networks:
      - internal_net
    volumes:
      - app_data:/app/data
    healthcheck:
      test: ["CMD-SHELL", "python - <<'PY'\nimport sys,urllib.request\ntry:\n  r=urllib.request.urlopen('http://localhost:8000/health', timeout=3)\n  sys.exit(0 if r.status==200 else 1)\nexcept Exception:\n  sys.exit(1)\nPY"]
      interval: 30s
      timeout: 5s
      retries: 5

  # Celery worker (same image as API for now)
  worker:
    image: seo-analyzer-worker:latest
    build:
      context: .
      dockerfile: backend/Dockerfile
    restart: always
    env_file:
      - .env
    environment:
      - DATABASE_URL=${DATABASE_URL:-sqlite:////app/data/app.db}
      - REDIS_URL=redis://redis:6379/0
      - PYTHONUNBUFFERED=1
    command: bash -lc "celery -A celery_app.celery_app worker -Q runs -l info"
    depends_on:
      - redis
    networks:
      - internal_net
    healthcheck:
      test: ["CMD-SHELL", "bash -lc 'celery -A celery_app.celery_app inspect ping -d celery@$HOSTNAME || exit 1'"]
      interval: 30s
      timeout: 5s
      retries: 5


  redis:
    image: redis:7-alpine
    restart: always
    command: ["redis-server", "--appendonly", "yes"]
    volumes:
      - redis_data:/data
    expose:
      - "6379"
    networks:
      - internal_net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

